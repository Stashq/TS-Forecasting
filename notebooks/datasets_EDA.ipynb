{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from predpy.preprocessing import set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predpy.dataset import TimeSeriesRecordsDataset, SingleTimeSeriesDataset\n",
    "from predpy.data_module import TimeSeriesModule\n",
    "from predpy.experimentator import Experimentator, DatasetParams, ModelParams\n",
    "from predpy.preprocessing import (\n",
    "    load_and_preprocess, set_index, scale, moving_average, drop_if_is_in,\n",
    "    use_dataframe_func, select_columns)\n",
    "from predpy.trainer import CheckpointParams, TrainerParams, EarlyStoppingParams, LoggerParams\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tsai.models import TCN, ResNet, TST, RNN, TransformerModel, FCN\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import List, Dict, Union, Any, Literal, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/stachu/Projects/Anomaly_detection/Forecasting_models\")\n",
    "\n",
    "from predpy.dataset import TimeSeriesRecordsDataset\n",
    "from predpy.dataset import SingleTimeSeriesDataset\n",
    "from predpy.experimentator import Experimentator, DatasetParams, ModelParams\n",
    "from predpy.preprocessing import set_index, scale\n",
    "from predpy.preprocessing import moving_average\n",
    "from predpy.preprocessing import (\n",
    "    load_and_preprocess, set_index, scale, moving_average, drop_if_is_in,\n",
    "    use_dataframe_func, select_columns)\n",
    "from predpy.trainer import (\n",
    "    CheckpointParams, TrainerParams, EarlyStoppingParams, LoggerParams)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tsai.models import TCN, ResNet, TST, RNN, TransformerModel, FCN\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# First experiment\n",
    "# ================\n",
    "\n",
    "datasets_params = [\n",
    "    DatasetParams(\n",
    "        path=\"../data/daily-min-temperatures.csv\",\n",
    "        target=\"Temp\",\n",
    "        split_proportions=[0.8, 0.1, 0.1],\n",
    "        window_size=366,\n",
    "        batch_size=64,\n",
    "        DatasetCls=SingleTimeSeriesDataset,\n",
    "        pipeline=[\n",
    "            (set_index, {\"column_name\": \"Date\"}),\n",
    "            (scale, {\"training_fraction\": 0.8, \"scaler\": MinMaxScaler()}),\n",
    "            (moving_average, {\"window_size\": 20, \"col_names\": [\"Temp\"]})\n",
    "        ])\n",
    "]\n",
    "\n",
    "# Second experiment\n",
    "# ================\n",
    "# load_params = {\n",
    "#     \"sep\": ';', \"header\": 0, \"low_memory\": False,\n",
    "#     \"infer_datetime_format\": True, \"parse_dates\": {'datetime': [0, 1]},\n",
    "#     \"index_col\": ['datetime']\n",
    "# }\n",
    "# pipeline = [\n",
    "#     (drop_if_is_in, ([\"?\", np.nan]), {\"columns\": [\"Global_active_power\"]}),\n",
    "#     (use_dataframe_func, \"astype\", \"float\"),\n",
    "#     (select_columns, [\"Global_active_power\"])\n",
    "# ]\n",
    "# datasets_params = [\n",
    "#     DatasetParams(\n",
    "#         path=\"./data/household_power_consumption.csv\",\n",
    "#         load_params=load_params,\n",
    "#         target=\"Global_active_power\",\n",
    "#         split_proportions=[0.8, 0.1, 0.1],\n",
    "#         window_size=366,\n",
    "#         batch_size=64,\n",
    "#         DatasetCls=SingleTimeSeriesDataset,\n",
    "#         pipeline=pipeline)\n",
    "# ]\n",
    "\n",
    "\n",
    "# ALMOST SAME SECTION\n",
    "# ===================\n",
    "\n",
    "# models_params = [\n",
    "#     ModelParams(\n",
    "#         name_=\"ResNet\", cls_=ResNet.ResNet,\n",
    "#         init_params={\"c_in\": 2, \"c_out\": 1}),\n",
    "#     # ModelParams(\n",
    "#     #     name_=\"LSTM_h200_l1\", cls_=RNN.LSTM,\n",
    "#     #     init_params={\n",
    "#     #         \"c_in\": 2, \"c_out\": 1, \"hidden_size\": 200, \"n_layers\": 1})\n",
    "# ]\n",
    "\n",
    "# chp_p = CheckpointParams(\n",
    "#     dirpath=\"../checkpoints\", monitor='val_loss', verbose=True,\n",
    "#     save_top_k=1)\n",
    "# tr_p = TrainerParams(\n",
    "#     max_epochs=1, gpus=1, auto_lr_find=True)\n",
    "# es_p = EarlyStoppingParams(\n",
    "#     monitor='val_loss', patience=3, verbose=True)\n",
    "\n",
    "# exp = Experimentator(models_params, datasets_params)\n",
    "\n",
    "# exp.run_experiments(\n",
    "#     \"lightning_logs\", tr_p, chp_p, es_p,\n",
    "#     experiments_path=\"saved_experiments\", safe=False)\n",
    "\n",
    "# print(\"true_vals: \", exp.datasets_params.iloc[0].true_values.shape[0])\n",
    "# print(\"preds: \", exp.predictions.iloc[0][\"predictions\"].__len__())\n",
    "exp.plot_predictions(0, file_path=\"predictions.html\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3bc42e69e4efcde7b1e8cf6bd8a64743430926df31e449dc034fb6e752071da"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
