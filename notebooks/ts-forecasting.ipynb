{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "sys.path.append(\"/home/stachu/Projects/Anomaly_detection/Forecasting_models\")\n",
    "\n",
    "from predpy.dataset import TimeSeriesRecordsDataset\n",
    "from predpy.dataset import SingleTimeSeriesDataset, MultiTimeSeriesDataset\n",
    "from predpy.experimentator import Experimentator, DatasetParams, ModelParams\n",
    "from predpy.preprocessing import set_index\n",
    "from predpy.preprocessing import moving_average\n",
    "from predpy.preprocessing import (\n",
    "    load_and_preprocess, set_index, moving_average, drop_if_is_in,\n",
    "    use_dataframe_func, loc)\n",
    "from predpy.trainer import (\n",
    "    CheckpointParams, TrainerParams, EarlyStoppingParams, LoggerParams)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tsai.models import TCN, ResNet, TST, RNN, TransformerModel, FCN\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "('Sequence too short.', 'Error during setup 0 dataset named household_power_consumption.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ae0372e90167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperimentator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m exp.run_experiments(\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;34m\"../lightning_logs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchp_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     experiments_path=\"../saved_experiments\", safe=False)\n",
      "\u001b[0;32m~/Projects/Anomaly_detection/Forecasting_models/predpy/experimentator/experimentator_previous.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(self, logs_path, trainer_params, checkpoint_params, early_stopping_params, skip_points, experiments_path, safe)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0mds_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 self._deliver_exception(\n\u001b[0m\u001b[1;32m    280\u001b[0m                     msg=dataset_setup_exception_msg.substitute(\n\u001b[1;32m    281\u001b[0m                         dataset_idx=ds_idx, dataset_name=ds_name),\n",
      "\u001b[0;32m~/Projects/Anomaly_detection/Forecasting_models/predpy/experimentator/experimentator_previous.py\u001b[0m in \u001b[0;36m_deliver_exception\u001b[0;34m(self, msg, exception, safe)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_data_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Anomaly_detection/Forecasting_models/predpy/experimentator/experimentator_previous.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(self, logs_path, trainer_params, checkpoint_params, early_stopping_params, skip_points, experiments_path, safe)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;31m# data setup and true values saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mtsm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0mds_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Anomaly_detection/Forecasting_models/predpy/experimentator/experimentator_previous.py\u001b[0m in \u001b[0;36m_data_setup\u001b[0;34m(self, ds_idx)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# data loading and transforming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mtsm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preprocessed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# saving true values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Anomaly_detection/Forecasting_models/predpy/experimentator/experimentator_previous.py\u001b[0m in \u001b[0;36mget_preprocessed_data\u001b[0;34m(self, dataset_idx)\u001b[0m\n\u001b[1;32m    145\u001b[0m             training_proportion=ds_params.split_proportions[0])\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         tsm = TimeSeriesModule(\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0msequence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Anomaly_detection/Forecasting_models/predpy/data_module/time_series_module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sequence, dataset_name, target, split_proportions, window_size, batch_size, DatasetCls)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# init setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sequence too short.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_splits_assert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_proportions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         self._save_splits_as_ids(\n",
      "\u001b[0;31mAssertionError\u001b[0m: ('Sequence too short.', 'Error during setup 0 dataset named household_power_consumption.')"
     ]
    }
   ],
   "source": [
    "# # First experiment\n",
    "# # ================\n",
    "\n",
    "# datasets_params = [\n",
    "#     DatasetParams(\n",
    "#         path=\"../data/Meteorology/daily-min-temperatures.csv\",\n",
    "#         target=\"Temp\",\n",
    "#         split_proportions=[0.8, 0.1, 0.1],\n",
    "#         window_size=366,\n",
    "#         batch_size=64,\n",
    "#         DatasetCls=SingleTimeSeriesDataset,\n",
    "#         pipeline=[\n",
    "#             (set_index, {\"column_name\": \"Date\"}),\n",
    "#             (scale, {\"training_fraction\": 0.8, \"scaler\": MinMaxScaler()}),\n",
    "#             (moving_average, {\"window_size\": 20, \"col_names\": [\"Temp\"]})\n",
    "#         ])\n",
    "# ]\n",
    "\n",
    "# Second experiment\n",
    "# ================\n",
    "\n",
    "window_size = 366\n",
    "\n",
    "load_params = {\n",
    "    \"sep\": ';', \"header\": 0, \"low_memory\": False,\n",
    "    \"infer_datetime_format\": True, \"parse_dates\": {'datetime': [0, 1]},\n",
    "    \"index_col\": ['datetime']\n",
    "}\n",
    "\n",
    "columns = [\"Global_active_power\", \"Voltage\"]\n",
    "drop_refill_pipeline = [\n",
    "    (loc, {\"columns\": columns}),\n",
    "    (drop_if_is_in, ([\"?\", np.nan]), {\"columns\": columns}),\n",
    "]\n",
    "preprocessing_pipeline = [\n",
    "    (use_dataframe_func, \"astype\", \"float\"),\n",
    "]\n",
    "datasets_params = [\n",
    "    DatasetParams(\n",
    "        path=\"/home/stachu/Projects/Anomaly_detection/Forecasting_models/data/Energy/household_power_consumption/household_power_consumption.csv\",\n",
    "        load_params=load_params,\n",
    "        target=\"Global_active_power\",\n",
    "        split_proportions=[0.8, 0.1, 0.1],\n",
    "        window_size=window_size,\n",
    "        batch_size=64,\n",
    "        DatasetCls=SingleTimeSeriesDataset,\n",
    "        drop_refill_pipeline=drop_refill_pipeline,\n",
    "        preprocessing_pipeline=preprocessing_pipeline,\n",
    "        scaler=MinMaxScaler()),\n",
    "]\n",
    "\n",
    "c_in = 2\n",
    "c_out = 1\n",
    "\n",
    "models_params = [\n",
    "    # ModelParams(\n",
    "    #     name_=\"TST_l3_fcDrop0.1\", cls_=TST.TST,\n",
    "    #     init_params={\n",
    "    #         \"c_in\": c_in, \"c_out\": c_out, \"seq_len\": window_size,\n",
    "    #         \"max_seq_len\": window_size, \"n_layers\": 3, \"fc_dropout\": 0.1}),\n",
    "    # ModelParams(\n",
    "    #     name_=\"TST_l2_fcDrop0.1\", cls_=TST.TST,\n",
    "    #     init_params={\n",
    "    #         \"c_in\": c_in, \"c_out\": c_out, \"seq_len\": window_size,\n",
    "    #         \"max_seq_len\": window_size, \"n_layers\": 2, \"fc_dropout\": 0.1}),\n",
    "    # ModelParams(\n",
    "    #     name_=\"TST_l2_fcDrop0.0\", cls_=TST.TST,\n",
    "    #     init_params={\n",
    "    #         \"c_in\": c_in, \"c_out\": c_out, \"seq_len\": window_size,\n",
    "    #         \"max_seq_len\": window_size, \"n_layers\": 2, \"fc_dropout\": 0.0}),\n",
    "    ModelParams(\n",
    "        name_=\"ResNet\", cls_=ResNet.ResNet,\n",
    "        init_params={\"c_in\": c_in, \"c_out\": c_out}),\n",
    "    ModelParams(\n",
    "        name_=\"LSTM_h200_l1\", cls_=RNN.LSTM,\n",
    "        init_params={\n",
    "            \"c_in\": c_in, \"c_out\": c_out, \"hidden_size\": 200, \"n_layers\": 1}),\n",
    "    ModelParams(\n",
    "        name_=\"LSTM_h200_l2\", cls_=RNN.LSTM,\n",
    "        init_params={\n",
    "            \"c_in\": c_in, \"c_out\": c_out, \"hidden_size\": 200, \"n_layers\": 2}),\n",
    "    ModelParams(\n",
    "        name_=\"LSTM_h400_l1\", cls_=RNN.LSTM,\n",
    "        init_params={\n",
    "            \"c_in\": c_in, \"c_out\": c_out, \"hidden_size\": 400, \"n_layers\": 1}),\n",
    "]\n",
    "\n",
    "chp_p = CheckpointParams(\n",
    "    dirpath=\"../checkpoints\", monitor='val_loss', verbose=True,\n",
    "    save_top_k=1)\n",
    "tr_p = TrainerParams(\n",
    "    max_epochs=15, gpus=1, auto_lr_find=True)\n",
    "es_p = EarlyStoppingParams(\n",
    "    monitor='val_loss', patience=2, verbose=True)\n",
    "\n",
    "exp = Experimentator(models_params, datasets_params)\n",
    "\n",
    "exp.run_experiments(\n",
    "    \"../lightning_logs\", tr_p, chp_p, es_p,\n",
    "    experiments_path=\"../saved_experiments\", safe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Global_active_power'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f62e894c6e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperimentator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_experimentator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../saved_experiments/2021-11-29_01:49:34.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"predictions.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/Anomaly_detection/Forecasting_models/predpy/experimentator/experimentator_previous.py\u001b[0m in \u001b[0;36mplot_predictions\u001b[0;34m(self, dataset_idx, models_ids, scaler, file_path)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target_scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0mtrue_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_vals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predictions\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Anomaly_detection/Forecasting_models/predpy/experimentator/experimentator_previous.py\u001b[0m in \u001b[0;36mget_target_scaler\u001b[0;34m(self, dataset_idx, scaler)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         return fit_scaler(\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m             \u001b[0mds_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_proportions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Global_active_power'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "exp = Experimentator.load_experimentator(\"../saved_experiments/2021-11-29_01:49:34.pkl\")\n",
    "\n",
    "exp.plot_predictions(0, scaler=True, file_path=\"predictions.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# tmp = tmp.drop(tmp[tmp[\"Global_active_power\"]==\"?\"].index)\n",
    "# tmp = tmp[[\"Global_active_power\"]]\n",
    "\n",
    "# tmp.astype(float)\n",
    "# sns.scatterplot(data=tmp, x=tmp.index, y=\"Global_active_power\")\n",
    "# tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chp_p = CheckpointParams(\n",
    "    dirpath=\"../checkpoints\", monitor='val_loss', verbose=True,\n",
    "    save_top_k=1)\n",
    "tr_p = TrainerParams(\n",
    "    max_epochs=3, gpus=1, auto_lr_find=True, overfit_batches=0.1)\n",
    "es_p = EarlyStoppingParams(\n",
    "    monitor='val_loss', patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_params = [\n",
    "    ModelParams(\n",
    "        name_=\"ResNet\", cls_=ResNet.ResNet, init_params={\"c_in\": 2, \"c_out\": 1}),\n",
    "    ModelParams(\n",
    "        name_=\"LSTM_h200_l1\", cls_=RNN.LSTM, init_params={\"c_in\": 2, \"c_out\": 1, \"hidden_size\": 200, \"n_layers\": 1})\n",
    "]\n",
    "datasets_params = [\n",
    "    DatasetParams(\n",
    "        path=\"../data/daily-min-temperatures.csv\",\n",
    "        target=\"Temp\",\n",
    "        split_proportions=[0.8, 0.1, 0.1],\n",
    "        window_size=366,\n",
    "        batch_size=64,\n",
    "        DatasetCls=SingleTimeSeriesDataset,\n",
    "        pipeline=[\n",
    "            (set_index, {\"column_name\": \"Date\"}),\n",
    "            (scale, {\"training_fraction\": 0.8, \"scaler\": MinMaxScaler()}),\n",
    "            (moving_average, {\"window_size\": 20, \"col_names\": [\"Temp\"]})\n",
    "        ])\n",
    "]\n",
    "exp = Experimentator(models_params, datasets_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning:\n",
      "\n",
      "Checkpoint directory ../checkpoints/daily-min-temperatures/ResNet exists and is not empty.\n",
      "\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning:\n",
      "\n",
      "DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | model     | ResNet  | 478 K \n",
      "1 | criterion | MSELoss | 0     \n",
      "--------------------------------------\n",
      "478 K     Trainable params\n",
      "0         Non-trainable params\n",
      "478 K     Total params\n",
      "1.915     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/8 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:326: UserWarning:\n",
      "\n",
      "The number of training samples (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 8/8 [00:00<00:00, 11.77it/s, loss=0.0486, v_num=4:09, train_loss=0.0316, val_loss=0.156]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.156\n",
      "Epoch 0, global step 3: val_loss reached 0.15577 (best 0.15577), saving model to \"/home/stachu/Projects/Anomaly_detection/Forecasting_models/checkpoints/daily-min-temperatures/ResNet/2021-11-07_17:24:09.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 8/8 [00:00<00:00, 11.26it/s, loss=0.0352, v_num=4:09, train_loss=0.0125, val_loss=0.151]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.151\n",
      "Epoch 1, global step 7: val_loss reached 0.15070 (best 0.15070), saving model to \"/home/stachu/Projects/Anomaly_detection/Forecasting_models/checkpoints/daily-min-temperatures/ResNet/2021-11-07_17:24:09.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 8/8 [00:00<00:00, 11.99it/s, loss=0.0304, v_num=4:09, train_loss=0.0153, val_loss=0.147]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.147\n",
      "Epoch 2, global step 11: val_loss reached 0.14692 (best 0.14692), saving model to \"/home/stachu/Projects/Anomaly_detection/Forecasting_models/checkpoints/daily-min-temperatures/ResNet/2021-11-07_17:24:09.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 8/8 [00:00<00:00, 11.57it/s, loss=0.0304, v_num=4:09, train_loss=0.0153, val_loss=0.147]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning:\n",
      "\n",
      "Checkpoint directory ../checkpoints/daily-min-temperatures/LSTM_h200_l1 exists and is not empty.\n",
      "\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning:\n",
      "\n",
      "DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | model     | LSTM    | 163 K \n",
      "1 | criterion | MSELoss | 0     \n",
      "--------------------------------------\n",
      "163 K     Trainable params\n",
      "0         Non-trainable params\n",
      "163 K     Total params\n",
      "0.654     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 8/8 [00:00<00:00, 15.10it/s, loss=0.17, v_num=4:09, train_loss=0.0921, val_loss=0.163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.163\n",
      "Metric val_loss improved. New best score: 0.163\n",
      "Epoch 0, global step 3: val_loss reached 0.16262 (best 0.16262), saving model to \"/home/stachu/Projects/Anomaly_detection/Forecasting_models/checkpoints/daily-min-temperatures/ResNet/2021-11-07_17:24:09-v1.ckpt\" as top 1\n",
      "Epoch 0, global step 3: val_loss reached 0.16262 (best 0.16262), saving model to \"/home/stachu/Projects/Anomaly_detection/Forecasting_models/checkpoints/daily-min-temperatures/LSTM_h200_l1/2021-11-07_17:24:09.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 8/8 [00:00<00:00, 14.38it/s, loss=0.165, v_num=4:09, train_loss=0.0857, val_loss=0.154]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.154\n",
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.154\n",
      "Epoch 1, global step 7: val_loss reached 0.15373 (best 0.15373), saving model to \"/home/stachu/Projects/Anomaly_detection/Forecasting_models/checkpoints/daily-min-temperatures/ResNet/2021-11-07_17:24:09-v1.ckpt\" as top 1\n",
      "Epoch 1, global step 7: val_loss reached 0.15373 (best 0.15373), saving model to \"/home/stachu/Projects/Anomaly_detection/Forecasting_models/checkpoints/daily-min-temperatures/LSTM_h200_l1/2021-11-07_17:24:09.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  38%|███▊      | 3/8 [00:00<00:00, 10.63it/s, loss=0.168, v_num=4:09, train_loss=0.0408, val_loss=0.154]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f37e442e550>\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  50%|█████     | 4/8 [00:00<00:00, 12.41it/s, loss=0.16, v_num=4:09, train_loss=0.0795, val_loss=0.154] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._shutdown_workers()  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "\n",
      "    \n",
      "w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f37e442e550>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f37e442e550>  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f37e442e550>\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "\n",
      "      File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "            w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "self._shutdown_workers()  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    \n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "AssertionError  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      ":         can only join a child processw.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "\n",
      "AssertionError:   File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "can only join a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f37e442e550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 8/8 [00:00<00:00, 11.66it/s, loss=0.16, v_num=4:09, train_loss=0.0795, val_loss=0.145]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.145\n",
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.145\n",
      "Epoch 2, global step 11: val_loss reached 0.14515 (best 0.14515), saving model to \"/home/stachu/Projects/Anomaly_detection/Forecasting_models/checkpoints/daily-min-temperatures/ResNet/2021-11-07_17:24:09-v1.ckpt\" as top 1\n",
      "Epoch 2, global step 11: val_loss reached 0.14515 (best 0.14515), saving model to \"/home/stachu/Projects/Anomaly_detection/Forecasting_models/checkpoints/daily-min-temperatures/LSTM_h200_l1/2021-11-07_17:24:09.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 8/8 [00:00<00:00, 11.13it/s, loss=0.16, v_num=4:09, train_loss=0.0795, val_loss=0.145]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning:\n",
      "\n",
      "DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f37e442e550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f37e442e550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/stachu/anaconda3/envs/dl/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<predpy.experimentator.experimentator.Experimentator at 0x7f376273f7c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run_experiments(\"../lightning_logs\", tr_p, chp_p, es_p, experiments_path=\"../saved_experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = Experimentator.load_experimentator(\"../saved_experiments/2021-11-07_17:21:16.pkl\")\n",
    "# exp = Experimentator.load_experimentator(\"../saved_experiments/2021-11-07_16:58:09.pkl\")\n",
    "exp.plot_predictions(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to None (<ipython-input-9-c50d50884aea>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-c50d50884aea>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    None=1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to None\n"
     ]
    }
   ],
   "source": [
    "None=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet tsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-blink",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 31 14:16:28 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1060    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   49C    P0    26W /  N/A |    337MiB /  6078MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1646      G   /usr/lib/xorg/Xorg                137MiB |\n",
      "|    0   N/A  N/A      2466      G   cinnamon                           28MiB |\n",
      "|    0   N/A  N/A      4120      G   ...AAAAAAAAA= --shared-files       40MiB |\n",
      "|    0   N/A  N/A      5034      G   ...AAAAAAAAA= --shared-files      105MiB |\n",
      "|    0   N/A  N/A      8988      G   ...AAAAAAAAA= --shared-files       20MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from typing import List, Dict, Union, Callable\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "# from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import torch\n",
    "from torch import autograd, nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tsai.models import TCN, ResNet, TST, RNN, TransformerModel, FCN\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../src')\n",
    "from dataModule.Data import scale, create_sequences\n",
    "from dataModule.Data import SingleTimeSeriesDataset, SingleTimeSeriesModule\n",
    "from experimentsModule.Predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-mining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDNN VERSION: 7605\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: GeForce GTX 1060\n",
      "__CUDA Device Total Memory [GB]: 6.373572608\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:', torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-branch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "# HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "# sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "pl.seed_everything(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 8\n",
    "BATCH_SIZE = 64\n",
    "SEQ_LEN = 366\n",
    "SPLIT_PROPORTIONS = [0.8, 0.1, 0.1]\n",
    "TARGET = \"Temp\"\n",
    "\n",
    "df = pd.read_csv(\"../data/daily-min-temperatures.csv\").set_index(\"Date\")\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "scaler, df = scale(df, SPLIT_PROPORTIONS[0])\n",
    "# df[\"moving_average\"] = df.rolling(20).mean()\n",
    "# df[\"moving_average\"].iloc[:20] = df[\"Temp\"].iloc[:20]\n",
    "df = df.dropna()\n",
    "\n",
    "data_module = SingleTimeSeriesModule(df, SPLIT_PROPORTIONS, window_size=SEQ_LEN,\n",
    "                                     batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTC = yf.Ticker(\"BTC-USD\")\n",
    "# # df = BTC.history(period=\"max\", interval=\"1d\", auto_adjust=False, actions=False)\n",
    "# df = BTC.history(interval=\"1d\", start=\"2014-09-17\", end=\"2021-10-16\", actions=False)\n",
    "# df[\"Open-Close-diff\"] = df.apply(lambda x: x[\"Close\"] - x[\"Open\"], axis=1)\n",
    "\n",
    "# from datetime import datetime\n",
    "# end = datetime.strptime(\"06-01-2017\", '%m-%d-%Y')\n",
    "# df = df.loc[:end]  # remove last years due to a change behaviour\n",
    "# df = df[[\"Close\", \"Open-Close-diff\"]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3bc42e69e4efcde7b1e8cf6bd8a64743430926df31e449dc034fb6e752071da"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
