{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/stachu/Projects/Anomaly_detection/Forecasting_models\")\n",
    "\n",
    "from predpy.dataset import TimeSeriesRecordsDataset\n",
    "from predpy.dataset import SingleTimeSeriesDataset, MultiTimeSeriesDataset\n",
    "from predpy.data_module import MultiTimeSeriesModule\n",
    "from predpy.experimentator import (\n",
    "    DatasetParams, ModelParams, ExperimentatorPlot,\n",
    "    Experimentator, load_experimentator, plot_aggregated_predictions)\n",
    "from predpy.preprocessing import set_index\n",
    "from predpy.preprocessing import moving_average\n",
    "from predpy.preprocessing import (\n",
    "    load_and_preprocess, set_index, moving_average, drop_if_is_in,\n",
    "    use_dataframe_func, loc, iloc)\n",
    "from predpy.trainer import (\n",
    "    CheckpointParams, TrainerParams, EarlyStoppingParams, LoggerParams)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tsai.models import TCN, ResNet, TST, RNN, TransformerModel, FCN\n",
    "import pandas as pd\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 366\n",
    "\n",
    "load_params = {\n",
    "    \"sep\": ';', \"header\": 0, \"low_memory\": False,\n",
    "    \"infer_datetime_format\": True, \"parse_dates\": {'datetime': [0, 1]},\n",
    "    \"index_col\": ['datetime']\n",
    "}\n",
    "\n",
    "columns = [\"Global_active_power\", \"Voltage\"]\n",
    "drop_refill_pipeline = [\n",
    "    (loc, {\"columns\": columns}),\n",
    "    (drop_if_is_in, ([\"?\", np.nan]), {\"columns\": columns}),\n",
    "    (iloc, {\"rows_end\": 1500}),\n",
    "    # (iloc, {\"rows_start\": -20000}),\n",
    "]\n",
    "preprocessing_pipeline = [\n",
    "    (use_dataframe_func, \"astype\", \"float\"),\n",
    "]\n",
    "datasets_params = [\n",
    "    DatasetParams(\n",
    "        path=\"/home/stachu/Projects/Anomaly_detection/Forecasting_models/data/Energy/household_power_consumption/household_power_consumption.csv\",\n",
    "        load_params=load_params,\n",
    "        target=\"Global_active_power\",\n",
    "        split_proportions=[0.8, 0.1, 0.1],\n",
    "        window_size=window_size,\n",
    "        batch_size=64,\n",
    "        DatasetCls=MultiTimeSeriesDataset,\n",
    "        drop_refill_pipeline=drop_refill_pipeline,\n",
    "        preprocessing_pipeline=preprocessing_pipeline,\n",
    "        scaler=MinMaxScaler()),\n",
    "]\n",
    "\n",
    "c_in = 2\n",
    "c_out = 1\n",
    "\n",
    "models_params = [\n",
    "    # ModelParams(\n",
    "    #     name_=\"TST_l3_fcDrop0.1\", cls_=TST.TST,\n",
    "    #     init_params={\n",
    "    #         \"c_in\": c_in, \"c_out\": c_out, \"seq_len\": window_size,\n",
    "    #         \"max_seq_len\": window_size, \"n_layers\": 3, \"fc_dropout\": 0.1}),\n",
    "    # ModelParams(\n",
    "    #     name_=\"TST_l2_fcDrop0.1\", cls_=TST.TST,\n",
    "    #     init_params={\n",
    "    #         \"c_in\": c_in, \"c_out\": c_out, \"seq_len\": window_size,\n",
    "    #         \"max_seq_len\": window_size, \"n_layers\": 2, \"fc_dropout\": 0.1}),\n",
    "    # ModelParams(\n",
    "    #     name_=\"TST_l2_fcDrop0.0\", cls_=TST.TST,\n",
    "    #     init_params={\n",
    "    #         \"c_in\": c_in, \"c_out\": c_out, \"seq_len\": window_size,\n",
    "    #         \"max_seq_len\": window_size, \"n_layers\": 2, \"fc_dropout\": 0.0}),\n",
    "    # ModelParams(\n",
    "    #     name_=\"ResNet\", cls_=ResNet.ResNet,\n",
    "    #     init_params={\"c_in\": c_in, \"c_out\": c_out}),\n",
    "    ModelParams(\n",
    "        name_=\"LSTM_h200_l1\", cls_=RNN.LSTM,\n",
    "        init_params={\n",
    "            \"c_in\": c_in, \"c_out\": c_out, \"hidden_size\": 200, \"n_layers\": 1}),\n",
    "    # ModelParams(\n",
    "    #     name_=\"LSTM_h200_l2\", cls_=RNN.LSTM,\n",
    "    #     init_params={\n",
    "    #         \"c_in\": c_in, \"c_out\": c_out, \"hidden_size\": 200, \"n_layers\": 2}),\n",
    "    # ModelParams(\n",
    "    #     name_=\"LSTM_h400_l1\", cls_=RNN.LSTM,\n",
    "    #     init_params={\n",
    "    #         \"c_in\": c_in, \"c_out\": c_out, \"hidden_size\": 400, \"n_layers\": 1}),\n",
    "]\n",
    "\n",
    "chp_p = CheckpointParams(\n",
    "    dirpath=\"../checkpoints\", monitor='val_loss', verbose=True,\n",
    "    save_top_k=1)\n",
    "tr_p = TrainerParams(\n",
    "    max_epochs=1, gpus=1, auto_lr_find=True,\n",
    "    logger=TensorBoardLogger(\"../lightning_logs\"))\n",
    "es_p = EarlyStoppingParams(\n",
    "    monitor='val_loss', patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning:\n",
      "\n",
      "Checkpoint directory ../checkpoints/household_power_consumption/LSTM_h200_l1 exists and is not empty.\n",
      "\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning:\n",
      "\n",
      "DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | model     | LSTM    | 163 K \n",
      "1 | criterion | MSELoss | 0     \n",
      "--------------------------------------\n",
      "163 K     Trainable params\n",
      "0         Non-trainable params\n",
      "163 K     Total params\n",
      "0.654     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stachu/anaconda3/envs/dl/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:326: UserWarning:\n",
      "\n",
      "The number of training samples (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 11.45it/s, loss=0.101, v_num=3:31, train_loss=0.173, val_loss=0.137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.137\n",
      "Epoch 0, global step 5: val_loss reached 0.13665 (best 0.13665), saving model to \"/home/stachu/Projects/Anomaly_detection/Forecasting_models/checkpoints/household_power_consumption/LSTM_h200_l1/2021-12-10_17:43:31.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 10.98it/s, loss=0.101, v_num=3:31, train_loss=0.173, val_loss=0.137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making predictions:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making predictions: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<predpy.experimentator.experimentator.Experimentator at 0x7fc090761400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exp = Experimentator(\n",
    "#     models_params=models_params,\n",
    "#     datasets_params=datasets_params,\n",
    "#     trainer_params=tr_p,\n",
    "#     checkpoint_params=chp_p,\n",
    "#     early_stopping_params=es_p\n",
    "# )\n",
    "\n",
    "# exp.run_experiments(experiments_path=\"../saved_experiments\", safe=False)\n",
    "\n",
    "exp = load_experimentator(\n",
    "    \"../saved_experiments/2021-12-10_11:54:55.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsm = exp.load_time_series_module(0)\n",
    "\n",
    "# anomalies = []\n",
    "# i = 0\n",
    "\n",
    "# for data in tsm.train_dataloader():\n",
    "#     anomalies += [data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                     Global_active_power   Voltage\n",
       " datetime                                          \n",
       " 2006-12-16 17:24:00             0.534667  0.209897\n",
       " 2006-12-16 17:25:00             0.687200  0.144100\n",
       " 2006-12-16 17:26:00             0.689067  0.125612\n",
       " 2006-12-16 17:27:00             0.690933  0.150082\n",
       " 2006-12-16 17:28:00             0.461333  0.255574\n",
       " ...                                  ...       ...\n",
       " 2006-12-17 18:19:00             0.577333  0.182708\n",
       " 2006-12-17 18:20:00             0.453333  0.203915\n",
       " 2006-12-17 18:21:00             0.451733  0.195759\n",
       " 2006-12-17 18:22:00             0.454400  0.243611\n",
       " 2006-12-17 18:23:00             0.454133  0.243067\n",
       " \n",
       " [1500 rows x 2 columns]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Union, Tuple, Literal, Callable, List, Type\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "def copy_data_from_range(\n",
    "    tsm: MultiTimeSeriesModule,\n",
    "    range_: Union[\n",
    "        Tuple[int, int],\n",
    "        Literal[\"all\", \"train\", \"val\", \"test\"]] = \"all\"\n",
    ") -> List[pd.DataFrame]:\n",
    "    return tsm.sequences\n",
    "\n",
    "\n",
    "def seqs_to_type(\n",
    "    seqs: List[pd.DataFrame],\n",
    "    type_: Union[\n",
    "        MultiTimeSeriesModule, DataLoader, Dataset, List[pd.DataFrame]]\n",
    ") -> Union[MultiTimeSeriesModule, DataLoader, Dataset, List[pd.DataFrame]]:\n",
    "    return seqs\n",
    "\n",
    "\n",
    "# def anomaly_creation_wrapper(anomaly_creation):\n",
    "#     @wraps\n",
    "#     def create_anomaly(\n",
    "#         tsm: MultiTimeSeriesModule,\n",
    "#         range_: Union[\n",
    "#             Tuple[int, int],\n",
    "#             Literal[\"all\", \"train\", \"val\", \"test\"]] = \"all\",\n",
    "#         deal_with_negativity: str = None,\n",
    "#         return_type: Union[\n",
    "#             MultiTimeSeriesModule, DataLoader, Dataset,\n",
    "#             List[pd.DataFrame]] = None,\n",
    "#         *args, **kwargs\n",
    "#     ):\n",
    "#         seqs_dfs = copy_data_from_range(tsm, range_)\n",
    "#         seqs_dfs = anomaly_creation(\n",
    "#             seqs_dfs, deal_with_negativity, *ars, **kwargs)\n",
    "#         result = seqs_to_type(seqs_dfs, type_=return_type)\n",
    "#         return result\n",
    "#     return create_anomaly\n",
    "\n",
    "\n",
    "def create_anomaly(\n",
    "    tsm: MultiTimeSeriesModule,\n",
    "    anomaly_creation: Callable,\n",
    "    range_: Union[\n",
    "        Tuple[int, int],\n",
    "        Literal[\"all\", \"train\", \"val\", \"test\"]\n",
    "        ] = \"all\",\n",
    "    deal_with_negativity: str = None,\n",
    "    return_type: Union[\n",
    "        Type[MultiTimeSeriesModule], Type[DataLoader], Type[Dataset],\n",
    "        Type[List[pd.DataFrame]]\n",
    "        ] = None,\n",
    "    *args, **kwargs\n",
    "):\n",
    "    seqs_dfs = copy_data_from_range(tsm, range_)\n",
    "    seqs_dfs = anomaly_creation(\n",
    "        seqs=seqs_dfs,\n",
    "        deal_with_negativity=deal_with_negativity,\n",
    "        *args, **kwargs)\n",
    "    result = seqs_to_type(seqs_dfs, type_=return_type)\n",
    "    return result\n",
    "\n",
    "def add_nothing(\n",
    "    seqs: List[pd.DataFrame],\n",
    "    deal_with_negativity: str = None,\n",
    "):\n",
    "    return seqs\n",
    "\n",
    "create_anomaly(\n",
    "    tsm=tsm, anomaly_creation=add_nothing, range_=\"all\",\n",
    "    deal_with_negativity=\"abs\", return_type=List[pd.DataFrame]\n",
    ")\n",
    "\n",
    "# def add_white_noise(\n",
    "#     tsm: MultiTimeSeriesModule,\n",
    "#     range_: Union[\n",
    "#         Tuple[int, int],\n",
    "#         Literal[\"all\", \"train\", \"val\", \"test\"]] = \"all\",\n",
    "#     deal_with_negativity: str = None,\n",
    "#     return_type: Union[\n",
    "#         MultiTimeSeriesModule, DataLoader, Dataset,\n",
    "#         List[pd.DataFrame]] = None\n",
    "# ):\n",
    "#     # wczytywanie danych z zakresu\n",
    "\n",
    "#     for seq in tsm.sequences:\n",
    "#         print(seq)\n",
    "#         if positive:\n",
    "#             print(seq.apply(lambda x: abs(x + np.random.randn())))\n",
    "#         else:\n",
    "#             print(seq.apply(lambda x: x + np.random.randn()))\n",
    "#         break\n",
    "\n",
    "#     # zwracanie w odpowiedniej postaci\n",
    "# add_white_noise(tsm, positive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsad.anomaly_detector import PredictionAnomalyDetector\n",
    "\n",
    "model = exp.load_pl_model(\n",
    "    model_idx=0,\n",
    "    dir_path=\"checkpoints/household_power_consumption/LSTM_h200_l1\")\n",
    "\n",
    "ad = PredictionAnomalyDetector(model)\n",
    "\n",
    "ad.fit(\n",
    "    dataloader=tsm.train_dataloader(),\n",
    "    anomaly_data=tsm.val_dataloader(),\n",
    "    normal_data=tsm.test_dataloader()\n",
    ")\n",
    "\n",
    "ad.find_anomalies(tsm.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTC = yf.Ticker(\"BTC-USD\")\n",
    "# # df = BTC.history(period=\"max\", interval=\"1d\", auto_adjust=False, actions=False)\n",
    "# df = BTC.history(interval=\"1d\", start=\"2014-09-17\", end=\"2021-10-16\", actions=False)\n",
    "# df[\"Open-Close-diff\"] = df.apply(lambda x: x[\"Close\"] - x[\"Open\"], axis=1)\n",
    "\n",
    "# from datetime import datetime\n",
    "# end = datetime.strptime(\"06-01-2017\", '%m-%d-%Y')\n",
    "# df = df.loc[:end]  # remove last years due to a change behaviour\n",
    "# df = df[[\"Close\", \"Open-Close-diff\"]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3bc42e69e4efcde7b1e8cf6bd8a64743430926df31e449dc034fb6e752071da"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
